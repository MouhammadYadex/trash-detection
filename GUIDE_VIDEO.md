# üé• Guide de D√©tection Vid√©o

## ‚úÖ Fonctionnalit√© Ajout√©e

Une **page d√©di√©e** pour traiter les vid√©os a √©t√© cr√©√©e avec :
- Upload drag & drop de vid√©os (MP4, AVI, MOV)
- Traitement frame par frame avec YOLO
- Vid√©o annot√©e t√©l√©chargeable
- Statistiques compl√®tes (FPS, dur√©e, nombre de d√©tections)
- Historique des vid√©os trait√©es

---

## üöÄ Comment utiliser

### 1. **Acc√©der √† la page Vid√©o**

Dans l'application web (http://localhost:3000), cliquez sur **"Vid√©os"** dans le menu de navigation.

### 2. **Uploader une vid√©o**

**Option 1 - Drag & Drop:**
- Glissez-d√©posez votre vid√©o dans la zone de d√©p√¥t

**Option 2 - S√©lection:**
- Cliquez sur la zone de d√©p√¥t
- S√©lectionnez votre fichier vid√©o

**Formats accept√©s:** MP4, AVI, MOV  
**Taille maximale:** 100 MB

### 3. **Lancer la d√©tection**

1. Une fois la vid√©o upload√©e, une pr√©visualisation s'affiche
2. Cliquez sur **"D√©tecter sur Vid√©o"**
3. **Attendez le traitement** (peut prendre quelques minutes selon la dur√©e)
4. Une barre de progression s'affiche

### 4. **Voir les r√©sultats**

Une fois le traitement termin√©, vous obtenez :

#### üìπ **Vid√©o Annot√©e**
- Chaque frame annot√©e avec les bounding boxes
- Compteur de frames
- Player vid√©o int√©gr√©

#### üìä **Statistiques**
- **Total frames**: Nombre de frames trait√©es
- **FPS**: Frames par seconde de la vid√©o
- **Dur√©e**: Dur√©e totale en secondes
- **Temps de traitement**: Temps pris pour traiter la vid√©o

#### üéØ **R√©sum√© des d√©tections**
- Nombre total de d√©tections
- R√©partition par classe (poubelle_pleine / poubelle_vide)
- Nombre de frames o√π chaque classe appara√Æt

### 5. **T√©l√©charger la vid√©o annot√©e**

Cliquez sur **"T√©l√©charger Vid√©o Annot√©e"** pour enregistrer la vid√©o avec les annotations.

---

## üîß Architecture Technique

### Backend (API)

**Endpoint:** `POST /api/predict/video`

**Traitement:**
1. Re√ßoit la vid√©o upload√©e
2. Ouvre avec OpenCV (`cv2.VideoCapture`)
3. Pour chaque frame :
   - Ex√©cute YOLO inference
   - Annote le frame avec bounding boxes
   - Ajoute compteur de frames
   - Collecte les d√©tections
4. √âcrit vid√©o annot√©e avec `cv2.VideoWriter`
5. Encode en base64
6. Retourne JSON avec vid√©o + statistiques

**Code API (api.py):**
```python
@app.post("/api/predict/video")
async def predict_video(file: UploadFile = File(...)):
    # Traitement frame par frame
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break
        
        # Inf√©rence YOLO sur frame
        results = model.predict(source=frame, conf=0.25, device='cpu')
        annotated_frame = results[0].plot()
        
        # √âcrire frame annot√©
        out.write(annotated_frame)
    
    # Retourner vid√©o encod√©e + stats
    return {
        "video_base64": video_base64,
        "stats": {...},
        "detections": [...]
    }
```

### Frontend (React)

**Composant:** `VideoPage.jsx`

**Fonctionnalit√©s:**
- React Dropzone pour upload
- Axios pour requ√™te API (timeout 5 minutes)
- Barre de progression simul√©e
- D√©codage base64 ‚Üí Blob ‚Üí URL pour lecture
- LocalStorage pour historique

**Flow:**
1. User drop vid√©o ‚Üí `onDrop()`
2. Pr√©visualisation avec `<video>`
3. Click "D√©tecter" ‚Üí `handleDetect()`
4. POST `/api/predict/video` avec FormData
5. Affichage r√©sultats + vid√©o annot√©e
6. Download via blob URL

---

## ‚ö° Optimisations Possibles

### 1. **Traitement par lots de frames**
Au lieu de traiter frame par frame, traiter par batch de 10-30 frames :
```python
batch_frames = []
for i in range(batch_size):
    ret, frame = cap.read()
    if ret:
        batch_frames.append(frame)

# Inf√©rence sur batch
results = model.predict(source=batch_frames, batch=True)
```

### 2. **R√©duire la r√©solution**
Redimensionner les frames avant inf√©rence :
```python
frame_resized = cv2.resize(frame, (640, 480))
results = model.predict(source=frame_resized)
```

### 3. **Sauter des frames (frame skipping)**
Ne traiter que 1 frame sur N :
```python
skip_frames = 2  # Traiter 1 frame sur 3
if frame_count % skip_frames == 0:
    results = model.predict(source=frame)
```

### 4. **GPU Acceleration**
Si disponible, utiliser GPU :
```python
model.to('cuda')  # Au lieu de 'cpu'
results = model.predict(source=frame, device='cuda')
```

### 5. **Codec H.264 (plus efficace)**
Utiliser codec H.264 au lieu de mp4v :
```python
fourcc = cv2.VideoWriter_fourcc(*'H264')  # ou 'avc1', 'x264'
```

### 6. **WebSocket pour progression en temps r√©el**
Au lieu de simuler, envoyer vraie progression :
```python
# Backend
from fastapi import WebSocket

@app.websocket("/ws/video_progress")
async def websocket_endpoint(websocket: WebSocket):
    await websocket.accept()
    # Envoyer progression pendant traitement
    await websocket.send_json({"progress": frame_count / total_frames})
```

### 7. **Celery pour t√¢ches asynchrones**
Pour vid√©os longues, utiliser Celery :
```python
from celery import Celery

celery = Celery('tasks', broker='redis://localhost:6379')

@celery.task
def process_video(video_path):
    # Traitement long
    pass

# API retourne task_id
# Frontend poll status avec GET /task/{task_id}
```

---

## üìä Performances Attendues

### Exemple avec vid√©o 30s @ 30 FPS

**Sp√©cifications:**
- Dur√©e: 30 secondes
- FPS: 30
- Total frames: 900
- R√©solution: 1920x1080

**Sans optimisation (CPU):**
- Temps par frame: ~50-100ms
- Temps total: 45-90 secondes
- Ratio: 1.5-3x temps r√©el

**Avec GPU (CUDA):**
- Temps par frame: ~10-20ms
- Temps total: 9-18 secondes
- Ratio: 0.3-0.6x temps r√©el

**Avec optimisations (skip 2 frames, r√©solution 640x480):**
- Frames trait√©es: 300
- Temps par frame: ~30ms
- Temps total: 9 secondes
- Ratio: 0.3x temps r√©el

---

## üêõ D√©pannage

### Erreur: "connect ECONNREFUSED 127.0.0.1:8000"

**Cause:** API backend non d√©marr√©e

**Solution:**
```bash
cd /home/mouhammad/Bureau/nourrou/projet-poubelle/trash_full_detection
source .venv/bin/activate
python api.py
```

### Erreur: "Request Timeout"

**Cause:** Vid√©o trop longue, timeout atteint (5 min)

**Solutions:**
1. Augmenter timeout dans `VideoPage.jsx` :
```jsx
timeout: 600000 // 10 minutes
```

2. R√©duire dur√©e/r√©solution vid√©o

3. Utiliser frame skipping

### Erreur: "File too large"

**Cause:** Vid√©o > 100 MB

**Solutions:**
1. Augmenter limite dans `VideoPage.jsx` :
```jsx
maxSize: 200 * 1024 * 1024 // 200 MB
```

2. Compresser vid√©o avec ffmpeg :
```bash
ffmpeg -i input.mp4 -vcodec h264 -crf 28 output.mp4
```

### Vid√©o annot√©e ne se t√©l√©charge pas

**Cause:** Erreur d√©codage base64

**Solution:** V√©rifier que le backend retourne bien `video_base64`

**Test API direct:**
```bash
curl -X POST "http://localhost:8000/api/predict/video" \
  -F "file=@test.mp4" \
  -o result.json

# Extraire vid√©o
jq -r '.video_base64' result.json | base64 -d > output.mp4
```

### Vid√©o noire/corrompue

**Cause:** Codec incompatible

**Solutions:**
1. Changer codec dans API :
```python
fourcc = cv2.VideoWriter_fourcc(*'XVID')  # Tester diff√©rents codecs
```

2. Convertir vid√©o source :
```bash
ffmpeg -i input.mp4 -c:v libx264 -preset fast output.mp4
```

---

## üìù Exemple d'utilisation avec le notebook

Si vous voulez tester en dehors de l'app web, utilisez le notebook **2_yolo_inference_app.ipynb** :

```python
# Cellule : Traitement vid√©o
video_path = "chemin/vers/votre/video.mp4"
output_path = "outputs/video/annotated_video.mp4"

cap = cv2.VideoCapture(video_path)
fourcc = cv2.VideoWriter_fourcc(*'mp4v')
out = cv2.VideoWriter(output_path, fourcc, 30, (width, height))

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break
    
    results = model_detect.predict(source=frame, conf=0.25, device='cpu')
    annotated = results[0].plot()
    out.write(annotated)

cap.release()
out.release()
print(f"Vid√©o sauvegard√©e: {output_path}")
```

---

## üéØ R√©sum√©

**Vous pouvez maintenant :**
‚úÖ Uploader des vid√©os (MP4, AVI, MOV)  
‚úÖ Traiter frame par frame avec YOLO  
‚úÖ Voir vid√©o annot√©e avec d√©tections  
‚úÖ T√©l√©charger la vid√©o annot√©e  
‚úÖ Consulter statistiques d√©taill√©es  
‚úÖ Historique des vid√©os trait√©es  

**Endpoints API disponibles :**
- `POST /api/predict/image` ‚Üí Images
- `POST /api/predict/video` ‚Üí Vid√©os ‚ú® NOUVEAU
- `GET /api/health` ‚Üí Status
- `GET /api/stats` ‚Üí M√©triques mod√®le

**Navigation app :**
- `/` ‚Üí Accueil
- `/upload` ‚Üí Images
- `/video` ‚Üí Vid√©os ‚ú® NOUVEAU
- `/history` ‚Üí Historique
- `/stats` ‚Üí Statistiques
- `/about` ‚Üí √Ä propos

---

**Votre application est maintenant compl√®te avec support Images ET Vid√©os ! üé•üéâ**
